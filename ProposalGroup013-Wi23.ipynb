{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KEefA1bCz_6"
      },
      "source": [
        "# COGS 118A- Project Proposal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hF5yEkhECz_7"
      },
      "source": [
        "# Project Description"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCFb7FCwCz_8"
      },
      "source": [
        "# Names\n",
        "\n",
        "- Maya Beeri-Feldman\n",
        "- Jessica Perez\n",
        "- Abby Chang\n",
        "- Ethan Chen\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTAOwuWPCz_9"
      },
      "source": [
        "# Abstract \n",
        "Our goal is to use data including several health factors to predict whether or not a person has heart disease given their specific attributes. The data that we are using for this project represents certain health factors in a person and are measured using numerical variables. We will be using this data to train a few different model to predict whether or not a patient has heart disease based on certain health factors. Furthermore to address the constraints of our data will be using some cross validation methods to aid us in choosing between those models and tuning our hyperparameters. Our performance will be measured based on how well we are able to predict whether someone has heart disease or not."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSxnclMXCz_9"
      },
      "source": [
        "# Background\n",
        "\n",
        "Heart disease remains as one of the most prevalent diseases and leading cause of death in both the United States and the rest of the world. Prevalently, the CDC found that 1 of every 5 deaths was caused by heart disease in as recently as 2020<a name=\"CDC\"></a>[<sup>[1]</sup>](#CDCnote). As such an impactful and widespread disease with so much fatality, it is crucial to consider applications in attempts to prevent and reduce the disease’s effects. Additionally, costs for treating the disease add up to a staggering 299 billion per year in the U.S. alone<a name=\"CDC\"></a>[<sup>[1]</sup>](#CDCnote). In a study done by Jones et al., it was found that even at 40 years of age one in two men and one in three women faced lifetime risk for developing the disease<a name=\"lancet\"></a>[<sup>[2]</sup>](#lancetnote). So, as the disease has such a heavy and widespread impact in both medical and economic fields it is a concern that applies to doctors, patients, governments, and citizens alike. \n",
        "\n",
        "Thus, as such a pertinent disease that is also costly in treatment, it is crucial to emphasize prevention through prediction. If people are able to accurately know if they stand at risk, they can begin to take steps to prevent the effects of the disease. Additionally, the cost of treatment is also important to consider when understanding how heart disease disproportionately affects those in lower socioeconomic status especially in countries and regions that might not have the same access as other more ‘economically sufficient’ countries with more accessible health care<a name=\"SA\"></a>[<sup>[3]</sup>](#SAnote). This increases the importance of prevention as it not only importantly can save a person’s life by mitigating the effects of the disease, but also alleviate the economic strain it might place on a family. \n",
        "\n",
        "Furthermore, prediction of heart disease is by no means perfect. In a study done by Heller et al., it was found that patients may still be inaccurately diagnosed, including high risk patients being told they are not at risk<a name=\"UK\"></a>[<sup>[4]</sup>](#UKnote). In this study, the authors used about 8 thousand subjects from the United Kingdom Heart Disease Prevention Project and measured their age, systolic blood pressure, plasma cholesterol concentration, smoking habit, physical activity, and BMI (body mass index) at an initial screening<a name=\"UK\"></a>[<sup>[4]</sup>](#UKnote). About five years later, the same patients had the same vitals measured. They used a logistic regression analysis with development of heart disease as their outcome. Insignificant factors were removed from their analysis. They concluded that exercise and BMI did not have a significant effect on heart disease. \n",
        "\n",
        "In our approach though, we will be looking at data with closer to 13 different variables about a patient's health that can hopefully help with a more accurate prediction of heart disease. Our data also is collected from one instance in 1988 and has closer to 1 thousand participants also from another region. We will also aim to single out the more crucial variables in heart disease prediction. Additionally our dataset included more variability in subjects from various locations such as Cleveland, Longbeach, Switzerland, and Hungary. Hopefully, this can allow our model to generalize better with more ‘representative’ data.\n",
        "\n",
        " Findings from another study that aimed at studying the prediction strategies emphasized how the sooner it is predicted if a patient is at higher risk, the more the fatality of the disease can potentially be curbed<a name=\"UT\"></a>[<sup>[5]</sup>](#UTnote). Once more, the importance of prediction in heart disease is established as it can actually reduce risk of death. The study also concluded that while genetics can accurately predict risk and might soon play a more stringent role, for now the more cost effective approach of using traditional variables like age is still just as valuable.\n",
        "  \n",
        "Thus an aim of using these traditional factors to predict whether or not a person has heart disease benefits both the patient themselves in preventing the harsher impacts of the disease as well as is a less costly procedure of prediction compared to other methods. It also can lessen economic burden in the long run as treatment is costly and can unfairly impact patients of different backgrounds.\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6KI42dQeCz_9"
      },
      "source": [
        "# Problem Statement\n",
        "\n",
        "The problem we are trying to solve is accurately predicting heart disease by being able to classify a patient based on their physical and health characteristics. By using public health data of patients that includes their different factors, such as age, sex, and blood pressure, we hope to utilize these factors in determining if a person has heart disease. We hope to accomplish this by picking a model that has the best performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cr4V_BK_Cz_-"
      },
      "source": [
        "# Data\n",
        "\n",
        "Dataset: https://www.kaggle.com/datasets/johnsmith88/heart-disease-dataset\n",
        "\n",
        "The dataset chosen stems from the UCI Repository and consists of data from Cleveland, Long Beach, Hungary, and Switzerland which dates back to 1988. \n",
        "\n",
        "Number of variables: 13\n",
        "\n",
        "Number of observations: 1025\n",
        "\n",
        "Observations consist of: \n",
        "\n",
        "- Age\n",
        "\n",
        "- Sex\n",
        "\n",
        "- Chest pain type\n",
        "\n",
        "- Resting blood pressure\n",
        "\n",
        "- Serum cholesterol\n",
        "\n",
        "- Fasting blood sugar less than 120 mg/dl\n",
        "\n",
        "- Resting EEG  results\n",
        "\n",
        "- Maximum heart rate achieved\n",
        "\n",
        "- Exercise induced angina\n",
        "\n",
        "- ST depression induced by exercise relative to rest\n",
        "\n",
        "- Slope of the peak exercise ST segment\n",
        "\n",
        "- Number of major vessels colored by fluoroscopy\n",
        "\n",
        "- Thal\n",
        "\n",
        "Critical variables:\n",
        "\n",
        "- Age, measured in years\n",
        "\n",
        "- Sex, measured in binary, 0 = female, 1 = male\n",
        "\n",
        "- Chest pain type, measured on a scale from 0 to 4, 0 = typical \n",
        "angina, 1 = atypical angina, 3 = non anginal pain,  4 = asymptotic\n",
        "\n",
        "- Resting blood pressure, measured in mmHg\n",
        "\n",
        "- Serum cholesterol, measured in mg/dl\n",
        "\n",
        "- Fasting blood sugar less than 120 mg/dl, measured in binary, 0 = no, 1 = yes\n",
        "\n",
        "- Resting EEG results, measured on a scale from 0 to 2, 0 = normal, 1 = ST-T wave abnormality, 2 = left ventricular hypertrophy\n",
        "\n",
        "- Maximum heart rate achieved, measured in bpm\n",
        "\n",
        "- Exercise induced angina, measured in binary, 0 = no, 1 = yes\n",
        "\n",
        "- Slope of the peak exercise ST segment, measured on a scale from 1 to 3, 1 = upsloping, 2 = flat, 3 = downsloping\n",
        "\n",
        "Seeing as the data is already cleaned out and formatted in a useful way there is no need for us to perform any special handling. We do however plan on renaming some of the columns in the dataset in order to make it easier to identify. Additionally, it is worth addressing that our data is of a smaller size. We do not have the luxury of many observations such that we will be taking into account as we do our model selections and data handling that the data itself is of a smaller amount. Therefore, we plan on performing multiple techniques and comparing their performances on the test data set in order to see which model performs better.\n",
        "\n",
        "Furthermore, as the data types are different, to limit unequal treatment and improve comparisons, we will normalize the data as well as account for missing data values\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXSy5Dr4Cz_-"
      },
      "source": [
        "# Proposed Solution\n",
        "\n",
        "  For our solution we hope to use the data collected on heart disease to train a model to accurately classify whether a patient has heart disease. We will be training multiple models and then using a k-fold cross validation to select the best one. Specifically, we wish to 3 Machine Learning models and pick the one that gives the most accurate predictions.\n",
        "\n",
        "  However, since our data set is rather small, we will also be considering models in the context of how they perform with this smaller set. Additionally, we will compare different types of k-fold techniques to help with the lower amount such that we will try a more extensive search for the best validation technique to make the best estimate of our performance for our specific heart disease data. In other words, we will compare the cross validation results of Leave One Out k-fold (especially as we have a smaller data set and thus less expensive), Standard k-fold (for a balance of bias and variance), Nested k-fold (to aid with hyperparameter tuning), and Stratified k-fold (to account for imbalances in our data set).\n",
        "\n",
        "  We will be using the library sklearn, with its module sklearn.model_selection to allow us to grid search for hyperparameters to best fit our model while doing the nested k-fold, via RepeatedKFold. The models we specifically will use are Decision Trees, Logistic Regression, and SVM. All of these we are using because they are equipped to handle binary classification. While we considered models like KNN that can also handle binary classification, since we have a higher amount of features we ruled out using this one for caution of high dimensionality. \n",
        "\n",
        "  The reason we are choosing Logistic Regression is that it will aid with visualizing feature importance. This is especially useful to us since we wish to understand which variables are more crucial than others in predicting heart disease. Also the probabilistic nature of Logistic Regression is helpful to us as we are dealing with a disease where knowing the probability of our classification is especially pertinent. To implement this model we will sklearn.tree.LogisticRegression. \n",
        "\n",
        "  We are picking Decision Trees because in this project we believe visualization be very crucial since the data can be slightly difficult to understand with various variables contributing to our classifications. Furthermore, the fact that it is nonparametric is helpful due to our variables measuring different units, such that we do not have to have estimates about the distributions of these unalike variables. Also it will allow us to emphasize feature selection between all the factors. We will be using sklearn.tree.DecisionTreeClassifier for this.\n",
        "\n",
        "  Finally, we are choosing to use SVM as it works well with high dimensional data that has various features, like ours. Additionally, SVM’s ability to handle outliers will be helpful as our data is collected over a rather wide range of populations. Additionally, its usefulness with avoiding overfitting is crucial for us as we have a smaller data set where we must both make the most of our limited training data whilst not overfitting on it. We will use sklearn.svm.SVC to do this.  \n",
        "\n",
        "\n",
        "Our models will be:\n",
        "\n",
        "\n",
        "Logistic Regression: We chose this as one of our picks for our classification algorithms because:\n",
        "- It is easy to find the feature importance (via model coefficients) for certain criteria that may better predict if someone has heart disease\n",
        "- Easy to understand\n",
        "- It is a relatively fast algorithm\n",
        "- It does not suffer from the curse of dimensionality\n",
        "\n",
        "We will be using sklearn.tree.LogisticRegression for this.\n",
        "\n",
        "SVM\n",
        "\n",
        "Decision Trees: We chose this as one of our picks for our classification algorithms because:\n",
        "- We don't need to normalize our data, nor would empty holes in the data affect decision tree calculation\n",
        "- Easy to understand\n",
        "- It is a relatively fast algorithm if maintained properly\n",
        "- It does not suffer from the curse of dimensionality\n",
        "- We will be adding pruning in order to reduce overfitting and to decrease tree complexity, having a maximum depth, and making sure that there is a minimum amount of samples per leaf\n",
        "\n",
        "We will be using sklearn.tree.DecisionTreeClassifier for this.\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RW0mmJDACz_-"
      },
      "source": [
        "# Evaluation Metrics\n",
        "\n",
        "We wish to use Confusion Matrix, specifically the values of Recall in order to limit false negatives. Recall is defined as “TruePositives / (TruePositives + FalseNegatives).” The reason why we are using Recall is due to the fact that it can be extremely harmful if someone has a heart disease but the model predicts that they don't – a false negative – which is measured by Recall. Specifically, Recall will be a value between 0 and 1, with 0 being the worst and 1 being perfect Recall. This model is able to tolerate false positives (Measured by Precision) because that would mean that a patient not diagnosed with heart disease is tested positive, all that leads to for the patient is further medical analysis. If we evaluate our model with the F1 metric, which equally gives weight to Recall and Precision, it would put some weight away from prioritizing the maximization of the Recall value. However, we will still be also looking at other metric that involve FalseNegatives such as False Negative Rate, False Omission Rate, and F1 score."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUME3TbzCz_-"
      },
      "source": [
        "# Ethics & Privacy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5McoBaVCz__"
      },
      "source": [
        "  Given that the dataset we have chosen is available for the public and that any personally identifiable information, such as names, have been removed from the dataset, we do not observe major ethical concerns for using this dataset. Likewise, seeing as the data was collected from UCI, which is one of the top medical research schools, we assume that the subjects have given their informed consent before their data was collected. In order to continue to remain ethical during this project, we are going to cite all datasets and information we use with direct hyperlinks, therefore allowing anyone viewing the project to see where we got our information from. We also plan on thoroughly checking our data and results to ensure that there are no biases.\n",
        "  \n",
        "  Additionally, possible ethical concerns that we will keep in mind is that our data comes from specific regions that might be only indicative of the population living there and thus might not generalize well to patients from other regions. Furthermore, we acknowledge that the variables we are handling, personal health information, can be sensitive. However, like previously said, the data is assumed to have already been stripped of all possible personal information such that no particular individual or group can be linked to this data past the regions it was collected from.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DijjUROsCz__"
      },
      "source": [
        "# Team Expectations "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fE0hF_J2Cz__"
      },
      "source": [
        "- Team Expectation 1: We will work in an orderly fashion by distributing equal amounts of work amongst group members in a timely manner, adhering optimally to the project timeline\n",
        "- Team Expectation 2: We may file complaints about another group member to the instructor if they do not comply to finish their work in a timely manner agreed upon all acting members\n",
        "- Team Expectation 3: We will communicate through Discord with meetings when necessary, and make amendments to the timeline in case of emergency\n",
        "- Team Expectation 4: We will reply to messages within 24 hours at maximum\n",
        "- Team Expectation 5: We will do our best to work on what has been agreed upon during group meetings. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ydv0QmbyCz__"
      },
      "source": [
        "# Project Timeline Proposal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJ53wx8RCz__"
      },
      "source": [
        "\n",
        "| Meeting Date  | Meeting Time| Completed Before Meeting  | Discuss at Meeting |\n",
        "|---|---|---|---|\n",
        "| 2/13  |  9 AM |  Brainstorm topics/questions (all)  | Determine best form of communication; Discuss and come up with a couple of project topics; begin looking for datasets | \n",
        "| 2/16  |  11 AM |  Do background research on topics and find datasets | Decided on a final project topic and begin project proposal | \n",
        "| 2/21  | 4 PM  | Edit, finalize, and submit proposal  | Discuss  possible analytical approaches and wrangling of the data   |\n",
        "| 2/22  | 4 PM  | Import and begin wrangling and EDA | Finish EDA and wrangling; begin analysis   |\n",
        "| 2/28  | 4 PM  | Finish analysis; begin programming | Review and continue working on code |\n",
        "| 3/8  | 4 PM  | Finish programming portion| Discuss the results and begin conclusion and discussion |\n",
        "| 3/15  | 4 PM  | Finish conclusion, results, and discussion | Edit and review the entire project  |\n",
        "| 3/19  | 12 PM  | NA | Submit final project and group surveys  |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0l32lkQC0AA"
      },
      "source": [
        "# Footnotes\n",
        "<a name=\"CDCnote\"></a>1.[^](#CDC): “Heart Disease Facts,” Centers for Disease Control and Prevention (Centers for Disease Control and Prevention, October 14, 2022), https://www.cdc.gov/heartdisease/facts.htm#:~:text=Heart%20disease%20is%20the%20leading,groups%20in%20the%20United%20States.&text=One%20person%20dies%20every%2034,United%20States%20from%20cardiovascular%20disease<br> \n",
        "<a name=\"lancetnote\"></a>2.[^](#lancet): “Lifetime Risk of Developing Coronary Heart Disease.” The Lancet. Elsevier, February 19, 1999. https://www.sciencedirect.com/science/article/pii/S0140673698102799<br>\n",
        "<a name=\"SAnote\"></a>3.[^](#SA): “Prevention of Coronary Heart Disease in South Asia.” The Lancet. Elsevier, October 1, 2002. https://www.sciencedirect.com/science/article/pii/S0140673602110889<br>\n",
        "<a name=\"UKnote\"></a>4.[^](#UK): “How Well Can We Predict Coronary Heart Disease? Findings in the United Kingdom Heart Disease Prevention Project.” The BMJ. British Medical Journal Publishing Group, May 12, 1984. https://www.bmj.com/content/288/6428/1409.abstract<br>\n",
        "<a name=\"UTnote\"></a>5.[^](#UT): “Traditional Risk Factors Predict Heart Disease about as Well as Sophisticated Genetic Test, Study Suggests.” UT Southwestern Medical Center, February 18, 2020. https://www.utsouthwestern.edu/newsroom/articles/year-2020/predicting-heart-disease.html#:~:text=Identifying%20elevated%20risk%20for%20CHD,explains%20study%20leader%20Thomas%20J<bt>"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}